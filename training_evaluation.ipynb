{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7398afb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "from scripts.make_dataset import generate_full_sentence_dataset, sample_sentence_dataset, t5_apply_tokenization, crf_preprocess\n",
    "from scripts.model import t5_train_model, crf_train_model, crf_evaluate_canonical_predictions, naive_evaluate_canonical_predictions\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a890753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "2.6.0+cu124\n",
      "12.4\n",
      "90100\n",
      "NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(torch.backends.cudnn.version())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3dbb752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of stations (official names), their alternative names, and misspellings\n",
    "stations = {\n",
    "    \"National Stadium\": [\"nat stadium\", \"national sport stadium\", \"national stadiam\", \"national stadum\", \"national studiam\", \"national statium\", \"ntl stadium\", \n",
    "                            \"sanam keela\", \"sports stadium\", \"stadium bts\", \"stadium national\", \"the national stadium\"],\n",
    "    \"Siam\": [\"sayam\", \"siaam\", \"siamm\", \"siyam\", \"syam\"],\n",
    "    \"Ratchadamri\": [\"rachadamri\", \"rachadumri\", \"radchadamri\", \"rajadamri\", \"ratchadamli\", \"ratchadamree\", \"ratchadumri\", \"ratchdamri\", \"ratjadamri\"],\n",
    "    \"Sala Daeng\": [\"sala daeng\", \"sala dange\", \"sala deng\", \"saladaeng\", \"saladang\", \"salah daeng\"],\n",
    "    \"Chong Nonsi\": [\"chong non si\", \"chong nonsie\", \"chong nonsii\", \"chong nonsri\", \"chong nonsy\", \"chongnonsee\", \"chongnonsi\"],\n",
    "    \"Saint Louis\": [\"saint luis\", \"saint louiz\", \"st louie\", \"st louis\", \"st luis\", \"st. lewis\", \"st. louis\"],\n",
    "    \"Surasak\": [\"suracak\", \"surasack\", \"surasek\", \"surassak\"],\n",
    "    \"Saphan Taksin\": [\"sapan taksin\", \"saphan taksen\", \"saphan takshin\", \"saphan taksine\", \"saphan takzin\", \"saphan taxin\", \"saphantaksin\", \"taksin bridge\"]\n",
    "}\n",
    "\n",
    "\n",
    "# List of templates for model training, with one station placeholder [STATION]\n",
    "# All words, including \"?\", must be separated by space, as we use simple white space tokenizer\n",
    "base_templates = [\n",
    "    \"Can I reach [STATION] from Chulalongkorn University ?\",\n",
    "    \"Can I take MRT to get to [STATION] ?\",\n",
    "    \"Can I walk from [STATION] to MBK ?\",\n",
    "    \"Can I walk to [STATION] ?\",\n",
    "    \"How do I get to [STATION] ?\",\n",
    "    \"How far is [STATION] from Pratunam ?\",\n",
    "    \"How to go from the airport to [STATION] ?\",\n",
    "    \"Is [STATION] close to the city center ?\",\n",
    "    \"Is [STATION] open at night ?\",\n",
    "    \"Is [STATION] open now ?\",\n",
    "    \"What BTS line is [STATION] on ?\",\n",
    "    \"Where is [STATION] ?\",\n",
    "    \"Which exit should I use at [STATION] ?\",\n",
    "    \"Which line is [STATION] on ?\",\n",
    "    \"How can I get to [STATION] ?\",\n",
    "    \"Is it possible to walk to [STATION] from here ?\",\n",
    "    \"Is [STATION] served by the BTS ?\",\n",
    "    \"Which BTS stop is closest to [STATION] ?\",\n",
    "    \"What is the best way to reach [STATION] ?\",\n",
    "    \"Do I need to transfer to get to [STATION] ?\",\n",
    "    \"Is [STATION] on the Silom or Sukhumvit line ?\",\n",
    "    \"Can I travel to [STATION] using the Skytrain ?\",\n",
    "    \"How far is [STATION] from central Bangkok ?\",\n",
    "    \"What is the location of [STATION] ?\",\n",
    "    \"Where can I find [STATION] ?\",\n",
    "    \"Is [STATION] near popular attractions ?\",\n",
    "    \"Does BTS stop at [STATION] ?\",\n",
    "    \"What is the fastest way to reach [STATION] ?\",\n",
    "    \"Can I access [STATION] via BTS ?\"\n",
    "]\n",
    "\n",
    "\n",
    "# List of templates for model training, with two station placeholder, [STATION_1] and [STATION_2]\n",
    "# All words, including \"?\", must be separated by space, as we use simple white space tokenizer\n",
    "# [STATION_1] must come first, followed by [STATION_2]\n",
    "two_station_templates = [\n",
    "    \"How to go from [STATION_1] to [STATION_2] ?\",\n",
    "    \"Can I ride BTS from [STATION_1] to [STATION_2] directly ?\",\n",
    "    \"Is there a transfer between [STATION_1] and [STATION_2] ?\",\n",
    "    \"Which station do I change at when going from [STATION_1] to [STATION_2] ?\",\n",
    "    \"How many stops between [STATION_1] and [STATION_2] ?\",\n",
    "    \"How long does it take to go from [STATION_1] to [STATION_2] ?\",\n",
    "    \"Does [STATION_1] connect to [STATION_2] ?\",\n",
    "    \"What is the BTS route from [STATION_1] to [STATION_2] ?\",\n",
    "    \"Is [STATION_1] on the same line as [STATION_2] ?\",\n",
    "    \"How many minutes between [STATION_1] and [STATION_2] by BTS ?\",\n",
    "    \"Which line should I take from [STATION_1] to reach [STATION_2] ?\",\n",
    "    \"Do I need to change lines from [STATION_1] to [STATION_2] ?\",\n",
    "    \"Is there a direct BTS line connecting [STATION_1] and [STATION_2] ?\",\n",
    "    \"Can I go from [STATION_1] to [STATION_2] without switching ?\",\n",
    "    \"What is the fastest way to get from [STATION_1] to [STATION_2] by Skytrain ?\",\n",
    "    \"Is it possible to travel from [STATION_1] to [STATION_2] without transfer ?\",\n",
    "    \"Which interchange connects [STATION_1] to [STATION_2] ?\",\n",
    "    \"How many stations are between [STATION_1] and [STATION_2] ?\",\n",
    "    \"Where do I need to transfer to go from [STATION_1] to [STATION_2] ?\",\n",
    "    \"How do I commute from [STATION_1] to [STATION_2] using BTS ?\"\n",
    "]\n",
    "\n",
    "\n",
    "# Prefixes and suffixes to add before/after station name\n",
    "prefixes = [\"\", \"BTS \", \"Skytrain \"]\n",
    "suffixes = [\"\", \" station\", \" BTS\", \" BTS stop\"]\n",
    "\n",
    "\n",
    "# List of keys, with their neighbors, to be used in generation of corrupt station names\n",
    "keyboard_neighbors = {\n",
    "    'a': 'qwsz', 'b': 'vghn', 'c': 'xdfv', 'd': 'serfcx', 'e': 'wsdr',\n",
    "    'f': 'drtgvc', 'g': 'ftyhbv', 'h': 'gyujnb', 'i': 'ujko', 'j': 'huikmn',\n",
    "    'k': 'jiolm', 'l': 'kop', 'm': 'njk', 'n': 'bhjm', 'o': 'iklp',\n",
    "    'p': 'ol', 'q': 'wa', 'r': 'edft', 's': 'awedxz', 't': 'rfgy',\n",
    "    'u': 'yhji', 'v': 'cfgb', 'w': 'qase', 'x': 'zsdc', 'y': 'tghu',\n",
    "    'z': 'asx'\n",
    "}\n",
    "\n",
    "\n",
    "# List of characters, with their alternative phonetics, to be used in generation of corrupt station names\n",
    "phonetic_rules = {\n",
    "    \"ph\": \"f\", \"ch\": \"sh\", \"sh\": \"ch\", \"r\": \"l\", \"l\": \"r\",\n",
    "    \"d\": \"t\", \"t\": \"d\", \"k\": \"g\", \"g\": \"k\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ee18ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "A. Get dataset\n",
      "\n",
      "Step A1. Generate full sentence dataset\n",
      "Saved 6003714 training and 1501092 test set of full sentence dataset to data\\processed folder.\n",
      "\n",
      "Step A2. Shuffle and randomly sample the full sentence dataset to get train, validation, and test set\n",
      "Saved smaller version of train, validation, and test set to data\\outputs folder.\n"
     ]
    }
   ],
   "source": [
    "# A. Get dataset\n",
    "print(\"\\nA. Get dataset\")\n",
    "\n",
    "# Step A1. Generate full sentence dataset\n",
    "print(\"\\nStep A1. Generate full sentence dataset\")\n",
    "df_train, df_test, df_train_bio, df_test_bio = generate_full_sentence_dataset(stations, base_templates, two_station_templates, prefixes, suffixes, keyboard_neighbors, phonetic_rules)\n",
    "\n",
    "# Step A2. Shuffle and randomly sample the full sentence dataset to get train, validation, and test set\n",
    "print(\"\\nStep A2. Shuffle and randomly sample the full sentence dataset to get train, validation, and test set\")\n",
    "train_sample_size = 8000\n",
    "val_sample_size = 1000\n",
    "test_sample_size =1000\n",
    "\n",
    "df_train_small, df_val_small, df_test_small, df_train_bio_small, df_test_bio_small = sample_sentence_dataset(df_train, df_test, df_train_bio, df_test_bio, train_sample_size, val_sample_size, test_sample_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bcb580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comment out to load data from saved CSV outputs, instead of generating new ones from above\n",
    "# import pandas as pd\n",
    "# df_train_small = pd.read_csv(\"data/outputs/bts_train_data_small.csv\")\n",
    "# df_val_small = pd.read_csv(\"data/outputs/bts_val_data_small.csv\")\n",
    "# df_test_small = pd.read_csv(\"data/outputs/bts_test_data_small.csv\")\n",
    "# df_train_bio_small = pd.read_csv(\"data/outputs/bts_train_data_bio_small.csv\")\n",
    "# df_test_bio_small = pd.read_csv(\"data/outputs/bts_test_data_bio_small.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66aea373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step A3. T5: preprocess train data\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3851cf893bd94feab3d30730f815441e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ac7b1f4a11c4beba19b7cf2c66ae797",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8486cff6556467687c46b738cd8dbe2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is preprocessed and ready for T5 model training.\n"
     ]
    }
   ],
   "source": [
    "# Step A3. T5: preprocess train data\n",
    "print(\"\\nStep A3. T5: preprocess train data\")\n",
    "train_ds, eval_ds, test_ds = t5_apply_tokenization(df_train_small, df_val_small, df_test_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f059323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step A4. CRF: preprocess train data and build features\n",
      "Data is preprocessed and ready for CRF model training.\n"
     ]
    }
   ],
   "source": [
    "# Step A4. CRF: preprocess train data and build features\n",
    "print(\"\\nStep A4. CRF: preprocess train data and build features\")\n",
    "X_train, X_test, X_test_sentence, y_train, y_test = crf_preprocess(df_train_bio_small, df_test_bio_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d74ded6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "B. Train T5 and CRF models\n",
      "\n",
      "Step B1: Train T5 model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\beung-yoga\\Documents\\GitHub4\\nlp-project-structured\\scripts\\model.py:80: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1002' max='1002' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1002/1002 07:08, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.423800</td>\n",
       "      <td>1.394394</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.411000</td>\n",
       "      <td>1.387383</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.409000</td>\n",
       "      <td>1.384885</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight'].\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='84' max='42' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [42/42 00:45]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation on Validation Set: \n",
      "Precision: 1.0000\n",
      "Recall:    1.0000\n",
      "F1 Score:  1.0000\n",
      "Accuracy:  1.0000\n",
      "\n",
      "Evaluation on Test Set: \n",
      "Precision: 0.9990\n",
      "Recall:    1.0000\n",
      "F1 Score:  0.9993\n",
      "Accuracy:  0.9980\n"
     ]
    }
   ],
   "source": [
    "# B. Train T5 and CRF models\n",
    "print(\"\\nB. Train T5 and CRF models\")\n",
    "\n",
    "# Step B1: Train T5 model\n",
    "print(\"\\nStep B1: Train T5 model\")\n",
    "t5_model, t5_tokenizer, t5_test_precision, t5_test_recall, t5_test_f1, t5_test_accuracy = t5_train_model(train_ds, eval_ds, test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71d31c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step B2: Train CRF model\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
      "[CV] END .................................c1=0.001, c2=0.001; total time=   5.9s\n",
      "[CV] END .................................c1=0.001, c2=0.001; total time=   5.7s\n",
      "[CV] END .................................c1=0.001, c2=0.001; total time=   5.8s\n",
      "[CV] END ..................................c1=0.001, c2=0.01; total time=   5.9s\n",
      "[CV] END ..................................c1=0.001, c2=0.01; total time=   5.7s\n",
      "[CV] END ..................................c1=0.001, c2=0.01; total time=   5.9s\n",
      "[CV] END ...................................c1=0.001, c2=0.1; total time=   6.0s\n",
      "[CV] END ...................................c1=0.001, c2=0.1; total time=   5.8s\n",
      "[CV] END ...................................c1=0.001, c2=0.1; total time=   5.6s\n",
      "[CV] END .....................................c1=0.001, c2=1; total time=   5.6s\n",
      "[CV] END .....................................c1=0.001, c2=1; total time=   5.7s\n",
      "[CV] END .....................................c1=0.001, c2=1; total time=   5.6s\n",
      "[CV] END ....................................c1=0.001, c2=10; total time=   4.0s\n",
      "[CV] END ....................................c1=0.001, c2=10; total time=   3.8s\n",
      "[CV] END ....................................c1=0.001, c2=10; total time=   4.1s\n",
      "[CV] END ...................................c1=0.001, c2=100; total time=   2.6s\n",
      "[CV] END ...................................c1=0.001, c2=100; total time=   2.3s\n",
      "[CV] END ...................................c1=0.001, c2=100; total time=   2.4s\n",
      "[CV] END ..................................c1=0.01, c2=0.001; total time=   5.6s\n",
      "[CV] END ..................................c1=0.01, c2=0.001; total time=   5.9s\n",
      "[CV] END ..................................c1=0.01, c2=0.001; total time=   5.6s\n",
      "[CV] END ...................................c1=0.01, c2=0.01; total time=   5.6s\n",
      "[CV] END ...................................c1=0.01, c2=0.01; total time=   5.9s\n",
      "[CV] END ...................................c1=0.01, c2=0.01; total time=   5.6s\n",
      "[CV] END ....................................c1=0.01, c2=0.1; total time=   5.8s\n",
      "[CV] END ....................................c1=0.01, c2=0.1; total time=   5.6s\n",
      "[CV] END ....................................c1=0.01, c2=0.1; total time=   5.6s\n",
      "[CV] END ......................................c1=0.01, c2=1; total time=   5.6s\n",
      "[CV] END ......................................c1=0.01, c2=1; total time=   5.7s\n",
      "[CV] END ......................................c1=0.01, c2=1; total time=   5.6s\n",
      "[CV] END .....................................c1=0.01, c2=10; total time=   3.9s\n",
      "[CV] END .....................................c1=0.01, c2=10; total time=   3.9s\n",
      "[CV] END .....................................c1=0.01, c2=10; total time=   3.9s\n",
      "[CV] END ....................................c1=0.01, c2=100; total time=   2.6s\n",
      "[CV] END ....................................c1=0.01, c2=100; total time=   2.3s\n",
      "[CV] END ....................................c1=0.01, c2=100; total time=   2.4s\n",
      "[CV] END ...................................c1=0.1, c2=0.001; total time=   5.6s\n",
      "[CV] END ...................................c1=0.1, c2=0.001; total time=   5.6s\n",
      "[CV] END ...................................c1=0.1, c2=0.001; total time=   5.7s\n",
      "[CV] END ....................................c1=0.1, c2=0.01; total time=   5.7s\n",
      "[CV] END ....................................c1=0.1, c2=0.01; total time=   5.7s\n",
      "[CV] END ....................................c1=0.1, c2=0.01; total time=   5.6s\n",
      "[CV] END .....................................c1=0.1, c2=0.1; total time=   5.9s\n",
      "[CV] END .....................................c1=0.1, c2=0.1; total time=   5.9s\n",
      "[CV] END .....................................c1=0.1, c2=0.1; total time=   5.6s\n",
      "[CV] END .......................................c1=0.1, c2=1; total time=   5.6s\n",
      "[CV] END .......................................c1=0.1, c2=1; total time=   5.6s\n",
      "[CV] END .......................................c1=0.1, c2=1; total time=   5.8s\n",
      "[CV] END ......................................c1=0.1, c2=10; total time=   4.0s\n",
      "[CV] END ......................................c1=0.1, c2=10; total time=   3.6s\n",
      "[CV] END ......................................c1=0.1, c2=10; total time=   4.1s\n",
      "[CV] END .....................................c1=0.1, c2=100; total time=   2.3s\n",
      "[CV] END .....................................c1=0.1, c2=100; total time=   2.4s\n",
      "[CV] END .....................................c1=0.1, c2=100; total time=   2.3s\n",
      "[CV] END .....................................c1=1, c2=0.001; total time=   5.7s\n",
      "[CV] END .....................................c1=1, c2=0.001; total time=   5.6s\n",
      "[CV] END .....................................c1=1, c2=0.001; total time=   5.7s\n",
      "[CV] END ......................................c1=1, c2=0.01; total time=   5.9s\n",
      "[CV] END ......................................c1=1, c2=0.01; total time=   5.7s\n",
      "[CV] END ......................................c1=1, c2=0.01; total time=   5.7s\n",
      "[CV] END .......................................c1=1, c2=0.1; total time=   6.0s\n",
      "[CV] END .......................................c1=1, c2=0.1; total time=   5.5s\n",
      "[CV] END .......................................c1=1, c2=0.1; total time=   5.9s\n",
      "[CV] END .........................................c1=1, c2=1; total time=   5.6s\n",
      "[CV] END .........................................c1=1, c2=1; total time=   5.6s\n",
      "[CV] END .........................................c1=1, c2=1; total time=   6.0s\n",
      "[CV] END ........................................c1=1, c2=10; total time=   3.8s\n",
      "[CV] END ........................................c1=1, c2=10; total time=   4.0s\n",
      "[CV] END ........................................c1=1, c2=10; total time=   4.1s\n",
      "[CV] END .......................................c1=1, c2=100; total time=   2.5s\n",
      "[CV] END .......................................c1=1, c2=100; total time=   2.5s\n",
      "[CV] END .......................................c1=1, c2=100; total time=   2.3s\n",
      "[CV] END ....................................c1=10, c2=0.001; total time=   6.0s\n",
      "[CV] END ....................................c1=10, c2=0.001; total time=   5.7s\n",
      "[CV] END ....................................c1=10, c2=0.001; total time=   5.7s\n",
      "[CV] END .....................................c1=10, c2=0.01; total time=   5.6s\n",
      "[CV] END .....................................c1=10, c2=0.01; total time=   5.5s\n",
      "[CV] END .....................................c1=10, c2=0.01; total time=   5.6s\n",
      "[CV] END ......................................c1=10, c2=0.1; total time=   5.6s\n",
      "[CV] END ......................................c1=10, c2=0.1; total time=   5.7s\n",
      "[CV] END ......................................c1=10, c2=0.1; total time=   6.3s\n",
      "[CV] END ........................................c1=10, c2=1; total time=   5.5s\n",
      "[CV] END ........................................c1=10, c2=1; total time=   5.5s\n",
      "[CV] END ........................................c1=10, c2=1; total time=   5.6s\n",
      "[CV] END .......................................c1=10, c2=10; total time=   4.1s\n",
      "[CV] END .......................................c1=10, c2=10; total time=   4.4s\n",
      "[CV] END .......................................c1=10, c2=10; total time=   3.9s\n",
      "[CV] END ......................................c1=10, c2=100; total time=   2.4s\n",
      "[CV] END ......................................c1=10, c2=100; total time=   2.6s\n",
      "[CV] END ......................................c1=10, c2=100; total time=   2.5s\n",
      "[CV] END ...................................c1=100, c2=0.001; total time=   4.8s\n",
      "[CV] END ...................................c1=100, c2=0.001; total time=   5.0s\n",
      "[CV] END ...................................c1=100, c2=0.001; total time=   5.6s\n",
      "[CV] END ....................................c1=100, c2=0.01; total time=   5.2s\n",
      "[CV] END ....................................c1=100, c2=0.01; total time=   5.7s\n",
      "[CV] END ....................................c1=100, c2=0.01; total time=   6.2s\n",
      "[CV] END .....................................c1=100, c2=0.1; total time=   5.1s\n",
      "[CV] END .....................................c1=100, c2=0.1; total time=   5.1s\n",
      "[CV] END .....................................c1=100, c2=0.1; total time=   4.8s\n",
      "[CV] END .......................................c1=100, c2=1; total time=   5.7s\n",
      "[CV] END .......................................c1=100, c2=1; total time=   4.8s\n",
      "[CV] END .......................................c1=100, c2=1; total time=   4.7s\n",
      "[CV] END ......................................c1=100, c2=10; total time=   3.8s\n",
      "[CV] END ......................................c1=100, c2=10; total time=   3.7s\n",
      "[CV] END ......................................c1=100, c2=10; total time=   3.7s\n",
      "[CV] END .....................................c1=100, c2=100; total time=   2.5s\n",
      "[CV] END .....................................c1=100, c2=100; total time=   2.7s\n",
      "[CV] END .....................................c1=100, c2=100; total time=   2.5s\n",
      "Best parameters found:  {'c1': 0.001, 'c2': 0.01}\n",
      "Best Cross-validation F1 score:: 0.999341\n",
      "\n",
      "Evaluation on Test Set at Token-level: Treat B-station and I-station separately\n",
      "\n",
      "Classification report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "     B-Chong_Nonsi       1.00      0.98      0.99       232\n",
      "B-National_Stadium       0.53      0.97      0.69       333\n",
      "     B-Ratchadamri       1.00      0.97      0.98       294\n",
      "     B-Saint_Louis       1.00      1.00      1.00       269\n",
      "      B-Sala_Daeng       1.00      1.00      1.00       201\n",
      "   B-Saphan_Taksin       1.00      1.00      1.00       247\n",
      "            B-Siam       1.00      0.99      0.99       207\n",
      "         B-Surasak       1.00      0.98      0.99       213\n",
      "     I-Chong_Nonsi       0.99      1.00      0.99       423\n",
      "I-National_Stadium       0.65      1.00      0.79       626\n",
      "     I-Ratchadamri       0.99      1.00      1.00       283\n",
      "     I-Saint_Louis       0.99      1.00      0.99       458\n",
      "      I-Sala_Daeng       0.99      1.00      1.00       343\n",
      "   I-Saphan_Taksin       0.98      1.00      0.99       440\n",
      "            I-Siam       0.99      1.00      1.00       191\n",
      "         I-Surasak       1.00      1.00      1.00       210\n",
      "                 O       1.00      0.93      0.96      8555\n",
      "\n",
      "          accuracy                           0.95     13525\n",
      "         macro avg       0.95      0.99      0.96     13525\n",
      "      weighted avg       0.97      0.95      0.96     13525\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 227    0    0    0    0    0    0    0    1    0    0    0    0    0\n",
      "     0    0    4]\n",
      " [   0  323    0    0    0    0    0    0    0    6    0    0    0    0\n",
      "     0    0    4]\n",
      " [   0    0  286    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    8]\n",
      " [   0    0    0  268    0    0    0    0    0    0    0    1    0    0\n",
      "     0    0    0]\n",
      " [   0    0    0    0  200    0    0    0    0    0    0    0    1    0\n",
      "     0    0    0]\n",
      " [   0    0    0    0    0  246    0    0    0    0    0    0    0    0\n",
      "     0    0    1]\n",
      " [   0    0    0    0    0    0  204    0    0    0    0    0    0    0\n",
      "     0    0    3]\n",
      " [   0    0    1    0    0    0    0  208    0    0    0    0    0    0\n",
      "     0    1    3]\n",
      " [   0    0    0    0    0    0    0    0  422    0    0    0    0    0\n",
      "     0    0    1]\n",
      " [   0    3    0    0    0    0    0    0    0  623    0    0    0    0\n",
      "     0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0  283    0    0    0\n",
      "     0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0  458    0    0\n",
      "     0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0  343    0\n",
      "     0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0  440\n",
      "     0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "   191    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    1    0    0    0\n",
      "     0  209    0]\n",
      " [   1  278    0    1    1    0    0    1    5  326    1    5    2   10\n",
      "     1    0 7923]]\n",
      "\n",
      "Precision: 0.9463\n",
      "Recall:    0.9873\n",
      "F1 score:  0.9609\n",
      "Accuracy:  0.9504\n",
      "\n",
      "Evaluation on Test Set: Exact Canonical Match\n",
      "\n",
      "Classification Report\n",
      "                                                precision    recall  f1-score   support\n",
      "\n",
      "                                                     0.00      0.00      0.00         0\n",
      "                                   chong nonsi       0.50      1.00      0.67         1\n",
      "                chong nonsi ; national stadium       1.00      1.00      1.00        53\n",
      "  chong nonsi ; national stadium ; ratchadamri       0.00      0.00      0.00         0\n",
      "  chong nonsi ; national stadium ; saint louis       0.00      0.00      0.00         0\n",
      "   chong nonsi ; national stadium ; sala daeng       0.00      0.00      0.00         0\n",
      "chong nonsi ; national stadium ; saphan taksin       0.00      0.00      0.00         0\n",
      "         chong nonsi ; national stadium ; siam       0.00      0.00      0.00         0\n",
      "      chong nonsi ; national stadium ; surasak       0.00      0.00      0.00         0\n",
      "                     chong nonsi ; ratchadamri       1.00      0.64      0.78        36\n",
      "                     chong nonsi ; saint louis       1.00      0.68      0.81        37\n",
      "                      chong nonsi ; sala daeng       1.00      0.67      0.80        33\n",
      "                   chong nonsi ; saphan taksin       1.00      0.69      0.82        29\n",
      "                            chong nonsi ; siam       1.00      0.67      0.80        21\n",
      "                         chong nonsi ; surasak       1.00      0.86      0.93        22\n",
      "                              national stadium       0.00      0.00      0.00         0\n",
      "                national stadium ; ratchadamri       1.00      1.00      1.00        69\n",
      "  national stadium ; ratchadamri ; saint louis       0.00      0.00      0.00         0\n",
      "   national stadium ; ratchadamri ; sala daeng       0.00      0.00      0.00         0\n",
      "national stadium ; ratchadamri ; saphan taksin       0.00      0.00      0.00         0\n",
      "         national stadium ; ratchadamri ; siam       0.00      0.00      0.00         0\n",
      "      national stadium ; ratchadamri ; surasak       0.00      0.00      0.00         0\n",
      "                national stadium ; saint louis       1.00      1.00      1.00        48\n",
      "   national stadium ; saint louis ; sala daeng       0.00      0.00      0.00         0\n",
      "national stadium ; saint louis ; saphan taksin       0.00      0.00      0.00         0\n",
      "         national stadium ; saint louis ; siam       0.00      0.00      0.00         0\n",
      "      national stadium ; saint louis ; surasak       0.00      0.00      0.00         0\n",
      "                 national stadium ; sala daeng       1.00      1.00      1.00        34\n",
      " national stadium ; sala daeng ; saphan taksin       0.00      0.00      0.00         0\n",
      "          national stadium ; sala daeng ; siam       0.00      0.00      0.00         0\n",
      "       national stadium ; sala daeng ; surasak       0.00      0.00      0.00         0\n",
      "              national stadium ; saphan taksin       1.00      0.98      0.99        52\n",
      "       national stadium ; saphan taksin ; siam       0.00      0.00      0.00         0\n",
      "    national stadium ; saphan taksin ; surasak       0.00      0.00      0.00         0\n",
      "                       national stadium ; siam       0.98      0.98      0.98        41\n",
      "             national stadium ; siam ; surasak       0.00      0.00      0.00         0\n",
      "                    national stadium ; surasak       1.00      0.97      0.99        36\n",
      "                                   ratchadamri       0.00      0.00      0.00         1\n",
      "                     ratchadamri ; saint louis       1.00      0.64      0.78        42\n",
      "                      ratchadamri ; sala daeng       0.96      0.78      0.86        32\n",
      "                   ratchadamri ; saphan taksin       1.00      0.58      0.74        36\n",
      "                            ratchadamri ; siam       1.00      0.65      0.79        43\n",
      "                         ratchadamri ; surasak       1.00      0.74      0.85        35\n",
      "                                   saint louis       0.20      1.00      0.33         1\n",
      "                      saint louis ; sala daeng       1.00      0.61      0.75        33\n",
      "                   saint louis ; saphan taksin       1.00      0.71      0.83        38\n",
      "                            saint louis ; siam       1.00      0.82      0.90        28\n",
      "                         saint louis ; surasak       1.00      0.57      0.73        42\n",
      "                                    sala daeng       0.00      0.00      0.00         0\n",
      "                    sala daeng ; saphan taksin       1.00      0.86      0.93        22\n",
      "                             sala daeng ; siam       1.00      0.89      0.94        18\n",
      "                          sala daeng ; surasak       1.00      0.62      0.77        29\n",
      "                                 saphan taksin       0.00      0.00      0.00         0\n",
      "                          saphan taksin ; siam       1.00      0.58      0.73        38\n",
      "                       saphan taksin ; surasak       1.00      0.59      0.75        32\n",
      "                                          siam       0.00      0.00      0.00         1\n",
      "                                siam ; surasak       1.00      0.59      0.74        17\n",
      "                                       surasak       0.00      0.00      0.00         0\n",
      "\n",
      "                                      accuracy                           0.78      1000\n",
      "                                     macro avg       0.49      0.40      0.43      1000\n",
      "                                  weighted avg       0.99      0.78      0.86      1000\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      "[[ 0  0  0 ...  0  0  0]\n",
      " [ 0  1  0 ...  0  0  0]\n",
      " [ 0  0 53 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  1 10  0]\n",
      " [ 0  0  0 ...  0  0  0]]\n",
      "Precision: 0.9945\n",
      "Recall:    0.7800\n",
      "F1 Score:  0.8640\n",
      "Accuracy:  0.7800\n"
     ]
    }
   ],
   "source": [
    "# Step B2: Train CRF model\n",
    "print(\"\\nStep B2: Train CRF model\")\n",
    "\n",
    "# Define the list of hyperparameter for cross validation\n",
    "param_grid = {\n",
    "    'c1': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'c2': [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "crf_model, crf_test_precision, crf_test_recall, crf_test_f1, crf_test_accuracy = crf_train_model(X_train, X_test, y_train, y_test, param_grid)\n",
    "\n",
    "crf_canon_test_precision, crf_canon_test_recall, crf_canon_test_f1, crf_canon_test_accuracy = crf_evaluate_canonical_predictions(crf_model, X_test, X_test_sentence, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15135d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step B3: Evaluate naive model\n",
      "\n",
      "Evaluation on Test Set: Exact Canonical Match\n",
      "\n",
      "Classification Report\n",
      "                                precision    recall  f1-score   support\n",
      "\n",
      "                                     0.00      0.00      0.00         0\n",
      "                   chong nonsi       0.00      0.00      0.00         1\n",
      "  chong nonsi;national stadium       1.00      0.47      0.64        53\n",
      "       chong nonsi;ratchadamri       1.00      0.53      0.69        36\n",
      "       chong nonsi;saint louis       1.00      0.49      0.65        37\n",
      "        chong nonsi;sala daeng       1.00      0.55      0.71        33\n",
      "     chong nonsi;saphan taksin       1.00      0.59      0.74        29\n",
      "              chong nonsi;siam       1.00      0.52      0.69        21\n",
      "           chong nonsi;surasak       1.00      0.36      0.53        22\n",
      "              national stadium       0.00      0.00      0.00         0\n",
      "  national stadium;ratchadamri       1.00      0.62      0.77        69\n",
      "  national stadium;saint louis       1.00      0.46      0.63        48\n",
      "   national stadium;sala daeng       1.00      0.50      0.67        34\n",
      "national stadium;saphan taksin       1.00      0.56      0.72        52\n",
      "         national stadium;siam       1.00      0.46      0.63        41\n",
      "      national stadium;surasak       1.00      0.42      0.59        36\n",
      "                   ratchadamri       0.01      1.00      0.03         1\n",
      "       ratchadamri;saint louis       1.00      0.36      0.53        42\n",
      "        ratchadamri;sala daeng       1.00      0.41      0.58        32\n",
      "     ratchadamri;saphan taksin       1.00      0.39      0.56        36\n",
      "              ratchadamri;siam       1.00      0.44      0.61        43\n",
      "           ratchadamri;surasak       1.00      0.46      0.63        35\n",
      "                   saint louis       0.02      1.00      0.04         1\n",
      "        saint louis;sala daeng       1.00      0.18      0.31        33\n",
      "     saint louis;saphan taksin       1.00      0.29      0.45        38\n",
      "              saint louis;siam       1.00      0.43      0.60        28\n",
      "           saint louis;surasak       1.00      0.24      0.38        42\n",
      "                    sala daeng       0.00      0.00      0.00         0\n",
      "      sala daeng;saphan taksin       1.00      0.32      0.48        22\n",
      "               sala daeng;siam       1.00      0.39      0.56        18\n",
      "            sala daeng;surasak       1.00      0.31      0.47        29\n",
      "                 saphan taksin       0.00      0.00      0.00         0\n",
      "            saphan taksin;siam       1.00      0.58      0.73        38\n",
      "         saphan taksin;surasak       1.00      0.53      0.69        32\n",
      "                          siam       0.00      0.00      0.00         1\n",
      "                  siam;surasak       1.00      0.41      0.58        17\n",
      "                       surasak       0.00      0.00      0.00         0\n",
      "\n",
      "                      accuracy                           0.45      1000\n",
      "                     macro avg       0.76      0.39      0.46      1000\n",
      "                  weighted avg       1.00      0.45      0.61      1000\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      "[[ 0  0  0 ...  0  0  0]\n",
      " [ 1  0  0 ...  0  0  0]\n",
      " [ 5  8 25 ...  0  0  0]\n",
      " ...\n",
      " [ 1  0  0 ...  0  0  0]\n",
      " [ 4  0  0 ...  4  7  2]\n",
      " [ 0  0  0 ...  0  0  0]]\n",
      "Precision: 0.7576\n",
      "Recall:    0.3852\n",
      "F1 Score:  0.4564\n",
      "Accuracy:  0.4480\n"
     ]
    }
   ],
   "source": [
    "# Step B3: Evaluate naive model\n",
    "print(\"\\nStep B3: Evaluate naive model\")\n",
    "naive_test_precision, naive_test_recall, naive_test_f1, naive_test_accuracy = naive_evaluate_canonical_predictions(stations, df_test_small)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
